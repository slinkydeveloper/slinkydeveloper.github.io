<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Debts Manager Tutorial Part 2: Contract Design]]></title>
    <url>%2FDebts-Manager-Tutorial-Contract-Design%2F</url>
    <content type="text"><![CDATA[Hi guys! Welcome back to this tutorial! In this second chapter of Debts Manager Tutorial I would like to show you how I have designed the REST API of Debts Manager. I&#x2019;m going to follow the API First approach, documenting all aspects of the API Design with OpenAPI 3. AnalysisThe REST APIs, in contrast with RPC, are driven by the data the services wants to expose. In the previous chapter I gave you an idea of the entities we must expose. Now I tabulate these and the relative operations on it. Entity Create Retrieve Update Delete User &#x2714; &#x2714; &#x274C; &#x274C; User relationship &#x2714; &#x2714; &#x274C; &#x274C; Transaction &#x2714; &#x2714; &#x2714; &#x2714; Status &#x274C; &#x2714; &#x274C; &#x274C; This table is a pretty good starting point, but I must refine the analysis enforcing our methods with policies and logics. These policies are primarly based on who is making the request. I&#x2019;m going to define a login phase together with JWT to provide authorization and authentication. Each endpoint, except login and register, is secured with a JWT auth. My objective is expose, for each user, only a subset of data relative to the user itself. ModelsBefore defining the endpoints I must formally describe the data models representing the service entities. OpenAPI has its own Json Schema dialect to define models: OpenAPI Schema. This is an extended subset of Json Schema Draft 5. Meanwhile I&#x2019;m writing, there is a proposal to allow usage of every version of Json Schema, including the newer versions, with an extension https://github.com/OAI/OpenAPI-Specification/issues/1532. I place these schemas in main OpenAPI file under components and schemas keywords. I can refeer to it using Json schema references ($ref keyword). The simplest model here is the user. I want to expose only the username, so I represent it with a simple string. This is the definition using OpenAPI Schema: 123Username: minLength: 5 type: string The status is represented by a map with users as keys and total debts\credits as values. In OpenAPI Schema: 12345Status: description: &apos;Map with username as keys and debt as value&apos; type: object additionalProperties: type: number In JSON maps are usually represented or as json array of tuples key-value or as a json object. The json object is the natural way to represent it, but it has an important restriction: keys are strings. In my case I need to represent a map string &#x2192; number, so json object representation fits good. The map values schema are defined using additionalProperties and, only with Json Schema Draft 7 or newer, keys schema are defined using propertyNames. The main transaction model is described below: 12345678910111213141516171819202122232425Transaction: type: object properties: id: type: string from: $ref: &apos;#/components/schemas/Username&apos; to: $ref: &apos;#/components/schemas/Username&apos; at: description: &quot;Insertion datetime&quot; format: date-time type: string value: type: number description: minLength: 1 type: string required: - from - to - id - description - value - at $ref keyword points to the Username schema I defined before. This model doesn&#x2019;t fit good for my usage, because for each Transaction endpoint I want to apply some policies. A very common example is the id field: when user inserts a new transaction I want to designate the database to fill the id value. When the user creates a new transaction it shouldn&#x2019;t add the id field: that means that I can&#x2019;t use the Transaction model to describe the &#x201C;create transaction&#x201D; request body. Let&#x2019;s look at all restrictions I want to apply on various transaction endpoints: id and at are filled by the backend when user adds a new transaction and they are immutable from the API perspective When user updates a transaction he can&#x2019;t update the from (sender) and to (receiver) fields When user adds a new transaction he doesn&#x2019;t need to fill the from field because the backend fills it with the logged user To apply these restrictions I create a new model for each endpoint. I&#x2019;m going to refactor Transaction into 3 different models: UpdateTransaction, NewTransaction and Transaction. These new models lead to a new problem: duplication of model fields definitions. Json schema solves the duplication with schema composition keywords: allOf, anyOf and oneOf. In particular I will use allOf to achieve inheritance of schemas. This is the final result: 123456789101112131415161718192021222324252627282930313233343536373839UpdateTransaction: type: object properties: value: type: number description: minLength: 1 type: stringNewTransaction: allOf: - $ref: &apos;#/components/schemas/UpdateTransaction&apos; - properties: to: $ref: &apos;#/components/schemas/Username&apos; required: - to - description - value type: objectTransaction: allOf: - $ref: &apos;#/components/schemas/NewTransaction&apos; - required: - from - to - id - description - value - at type: object properties: from: $ref: &apos;#/components/schemas/Username&apos; id: type: string at: description: &quot;Insertion datetime&quot; format: date-time type: string The schemas inheritance tree is UpdateTransaction&#x2190;NewTransaction&#x2190;Transaction EndpointsOpenAPI document structures the endpoint definitions as follow: 1234567paths: /pathA: {} /pathB: get: {} post: {} put: {} /pathC/{paramA}: {} OpenAPI path strings allow path parameters using {paramName} and doesn&#x2019;t require an explicit definition of query parameters. In OpenAPI terminology an operation is an API endpoint identified by a path and an HTTP method. Every operation could be uniquely identified with an operationId. The OpenAPI Specification (OAS) documents this field as optional, but I strongly suggest to specify it if you don&#x2019;t want to see your tooling explode. Most code generation tooling asserts that operationId is present. If it&#x2019;s not present they try to infeer it from path and http method producing unexpected results. For each operation we are going to define: operationId parameters (if any): List of header, path, query and cookie parameters requestBody (if any): Content type and content schema of request bodies responses: Status code with response content type and schemas I also fill the security field for each operation to require a JWT token to execute it. Transactions and StatusLet&#x2019;s start with transaction CRUDs: Operation operationId CRUD Path HTTP Method Create a new transaction createTransaction Create /transactions POST Get a single transaction getTransaction Retrieve /transactions/{transactionId} GET Get user related transactions getTransactions Retrieve multiple /transactions GET Update a transaction updateTransaction Update /transactions/{transactionId} PUT Delete a transaction deleteTransaction Delete /transactions/{transactionId} DELETE In OpenAPI: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/transactions: get: operationId: getTransactions responses: &apos;200&apos;: content: application/json: schema: type: array items: $ref: &apos;#/components/schemas/Transaction&apos; &apos;401&apos;: description: &apos;Expired token&apos; security: - loggedUserToken: [] post: operationId: createTransaction requestBody: content: application/json: schema: $ref: &apos;#/components/schemas/NewTransaction&apos; required: true responses: &apos;201&apos;: description: &apos;Successful response.&apos; &apos;401&apos;: description: &apos;Expired Token&apos; &apos;403&apos;: description: &quot;Trying to create a transaction with receiver not connected to logged user&quot; security: - loggedUserToken: []&apos;/transactions/{transactionId}&apos;: get: operationId: getTransaction responses: &apos;200&apos;: content: application/json: schema: $ref: &apos;#/components/schemas/Transaction&apos; &apos;401&apos;: description: &apos;Expired Token&apos; &apos;403&apos;: description: &quot;Trying to get a transaction where `from` or `to` is not the logged user&quot; security: - loggedUserToken: [] put: operationId: updateTransaction requestBody: content: application/json: schema: $ref: &apos;#/components/schemas/UpdateTransaction&apos; required: true responses: &apos;202&apos;: description: &apos;Successful response.&apos; &apos;401&apos;: description: &apos;Expired Token&apos; &apos;403&apos;: description: &apos;Trying to update a transaction where `from` is not the logged user&apos; security: - loggedUserToken: [] delete: operationId: deleteTransaction responses: &apos;204&apos;: description: &apos;Successful response.&apos; &apos;401&apos;: description: &apos;Expired Token &apos; &apos;403&apos;: description: &apos;Trying to remove a transaction where `from` is not the logged user&apos; security: - loggedUserToken: [] parameters: - name: transactionId in: path required: true schema: type: string Note that for all operations under /transactions/{transactionId} path I haven&#x2019;t redefined every time the parameter transactionId: I have defined once at path level. Status has only the retrieve operation, but I want to let user customize the output based on transactions insertion datetime: clients can use query parameter till to ask the status till the date time provided, excluding newer transactions. You can use it to throw back in your house mate face that he didn&#x2019;t pay the bills for a quite long time. 1234567891011121314151617181920/status: get: operationId: getUserStatus parameters: - name: till in: query required: false schema: type: string format: &apos;date-time&apos; responses: &apos;200&apos;: content: application/json: schema: $ref: &apos;#/components/schemas/Status&apos; &apos;401&apos;: description: &apos;Expired token&apos; security: - loggedUserToken: [] User and User relationshipsThe service supports creation and retrieval of users and user relationships. For simplicity I avoided to include U and D operations for user and user relationships. I want to expose an endpoint to retrieve all registered users and an endpoint to retrieve only users that have a relationship with logged user: 123456789101112131415161718192021222324252627282930313233343536373839/users: get: operationId: getUsers responses: &apos;200&apos;: content: application/json: schema: type: array items: $ref: &apos;#/components/schemas/Username&apos; &apos;401&apos;: description: &apos;Expired token&apos; security: - loggedUserToken: []/users/connected: get: operationId: getConnectedUsers responses: &apos;200&apos;: content: application/json: schema: type: object properties: allowedTo: description: &quot;Users that logged user can bill&quot; type: array items: $ref: &apos;#/components/schemas/Username&apos; allowedFrom: description: &quot;Users that can bill the logged user&quot; type: array items: $ref: &apos;#/components/schemas/Username&apos; &apos;401&apos;: description: &apos;Expired token&apos; security: - loggedUserToken: [] In getConnectedUser I prefeered to define the request schema directly inside the request body definition because It&#x2019;s a schema strictly related to this operation and It isn&#x2019;t parent of any other schema. This is the endpoint to create a user connection (user relationship): 12345678910111213141516/users/connected/{userToConnect}: post: operationId: connectUser parameters: - name: userToConnect required: true in: path schema: $ref: &apos;#/components/schemas/Username&apos; responses: &apos;201&apos;: description: &apos;User connected&apos; &apos;401&apos;: description: &apos;Expired token&apos; security: - loggedUserToken: [] Login, registration and JWTWhen an user wants to start using this API he must authenticate with his credentials following this process: User calls the /login endpoint passing his credentials in the request body The backend checks if credentials are correct The backend writes the response with a JWT token containing the username inside the payload User stores the received JWT token For each request the server must authorize the user. The user must include inside each request the header Authorization: Bearer &lt;jwt token&gt;. When the backend receives the request it checks the signature validity and the token expiration time. If the token is valid It parses the payload, where It can read the username of the logged user. This is the login operation definition: 123456789101112131415161718192021222324/login: post: operationId: login requestBody: content: application/json: schema: required: - username - password type: object properties: username: $ref: &apos;#/components/schemas/Username&apos; password: type: string required: true responses: &apos;200&apos;: description: &apos;Returns the JWT token&apos; content: text/plain: {} &apos;400&apos;: description: &apos;Wrong username or password&apos; The register operation creates a new user and logins it: 123456789101112131415161718192021222324/register: post: operationId: register requestBody: content: application/json: schema: required: - username - password type: object properties: username: $ref: &apos;#/components/schemas/Username&apos; password: type: string required: true responses: &apos;200&apos;: description: &apos;Returns the JWT Token&apos; content: text/plain: {} &apos;400&apos;: description: &apos;Username already exists&apos; I don&#x2019;t cover in this tutorial the logout process, but I want to give you a tip: create a whitelist or blacklist of tokens. As you already saw, each secured operation has the security field: 12security: - loggedUserToken: [] The security field is called security requirement and it tells the user that he needs loggedUserToken security schema to access to this endpoint. Security schemas must be defined under #/components/securitySchemes: 1234securitySchemes: loggedUserToken: type: http scheme: bearer Some resources to learn Web API Design and OpenAPII give you a couple of useful links: Rest API Tutorial: Very simple and coincise tutorial for newbies of REST APIs world http://apistylebook.com/: Collection of API styleguides from different IT companies OpenAPI Specification repository: Contains the spec and examples OpenAPI Directory: Collection of OpenAPIs of different public APIs ConclusionYou can find the complete OpenAPI definition here: /src/main/resources/debts_manager_api.yaml After you learnt how to design a REST API, approacching to OpenAPI is very simple. The operation definition is very intuitive because of 1:1 mapping with HTTP (methods, parameters, status codes, content types and so on). The tricky and magic part, for me, is definining and organizing the JSON Schemas. When you define simple models, you tend to put everything inside the same file. But when you raise the complexity using composed schemas, you get flooded by smaller and unclear schemas. My suggestion for you is to document the schemas with title and description keywords and organize these in multiple files. In next chapter I&#x2019;m going to bootstrap the project and start writing first Vert.x code, stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>openapi</tag>
        <tag>vertx</tag>
        <tag>development</tag>
        <tag>web</tag>
        <tag>web api contract</tag>
        <tag>openapi 3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Debts Manager Tutorial Part 1: Introduction]]></title>
    <url>%2FDebts-Manager-Tutorial-Introduction%2F</url>
    <content type="text"><![CDATA[Some months ago I decided to create a complete Vert.x application to show you capabilities of Vert.x for building Web APIs and, at the same time, I wanted to try some patterns I never used or applied. I&#x2019;m going to create a production ready application to finally manage the debts with my house mate with a fully powered Vert.x application! Some notes before starting: I&#x2019;m going to make this guide as complete as possible, but keep in mind that this is a side project and It could contain bugs and It could be incomplete. I will try to cover all interesting aspects about API design, implementation, testing and I will show you how I implemented Event Sourcing and CQRS. I don&#x2019;t plan to write a frontend for it (I don&#x2019;t want to hurt your eyes), but if you want to help me I&#x2019;m glad to accept it! The code is already available on GitHub but It could change while I&#x2019;m writing the guide. What Debts Manager should doThe purpose of Debts Manager is to manage the debts between two users of the service. The idea is similar to Splitwise, but it will support only bills between two users. Every user should be registered to use the application. Then, if you want to receive bills from another user, you must connect to that user. When you are connected, you can bill him creating a transaction. For example: User A registers to the platform User B registers to the platform User B allows user A to bill himself. It does connecting to user A User A bills user B of 5 Euros for last grocery shopping The final result is: user B now has a debt of 5 Euros with user A. Debts Manager will show to both users their status with various debts/credits The connection between users are unidirectional, which means that if users want to bill each other they must create two diffent connections. There is no group concept, I wanted to keep things as simple as possible. DesignBefore going further I want to show you a couple of things of the overall design of the application. These are required to undestand various aspects of the tutorial. Persistence &amp; Event SourcingFor persistence I choose PostgreSQL to store my data. The application stores into the database: The users instances (user) The connections between users (user relationship) The bills (transaction) The DB access is provided by the blazing fast reactive-pg-client library The application stores the transactions between users (events). You can use it as a log of various bills, but you also want to look at a summary of various credits/debits between connected users. To build it, we need to aggregate various transactions into one single structure that I call status. Every user has a status and is represented as a map with users as keys and total debts\credits as values. This map is built incrementally every time a user adds/modifies/removes a transaction and is stored in a Redis cache. Web APIThe application exposes a Web REST API that you can interact with. It is documented with an OpenAPI 3 file and exposes most of CRUD endpoints for users, user connections and transactions (some are missing to keep things simple). It also has an endpoint to access status of users. The endpoints are protected with JWT tokens, so to use the application you must complete a login request and you get a token to use for the following requests. The Web API is implemented using vertx-web, vertx-web-api-contract and vertx-web-api-service. TestingOkay I admit it, I&#x2019;m lazy &#x1F604; I tested only the minimum features! I built these tests primarly to show you how I faced and solved common async test problems. I used Junit5 together with vertx-junit5 and testcontainers to spin up Redis and PostgreSQL. Tutorial parts Contract design: Design the OpenAPI 3 contract Vert.x Web API Contract &amp; Service: Setup Vert.x project and bind Vert.x Event Bus services Persistence: Design and implement persistence Event Sourcing: Develop the read model and CQRS Testing: Spin up test containers and write clean assertions BONUS: Deploy to OpenShift BONUS: Refactor to microservices using Vert.x Event Bus Stay tuned for next chapter! And give me feedback about this tutorial! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>openapi</tag>
        <tag>vertx</tag>
        <tag>development</tag>
        <tag>web</tag>
        <tag>web api contract</tag>
        <tag>openapi 3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Assertions with Vert.x Futures and JUnit5]]></title>
    <url>%2FAssertions-With-Vertx-Futures-And-JUnit5%2F</url>
    <content type="text"><![CDATA[During development of Vert.x event manager library (a blog post about it is coming soon) I wanted to play with new vertx-junit5 library. I like the new async assertion APIs of vertx-junit5, but I feel very unconfortable using VertxTestContext.succeding(Handler) when I need to run sequentially different async tasks. With this method, your code rapidly grows in a big callback hell! Plus the interfaces I wanted to test are all in Futures style more than callback style. In this post I&#x2019;m going to explain you two methods I&#x2019;ve added with a PR that simplify tests with Futures assertComplete() and assertFailure()The PR adds methods: Future&lt;T&gt; assertComplete(Future&lt;T&gt; fut) Future&lt;T&gt; assertFailure(Future&lt;T&gt; fut) These methods take a future as parameter and register to it the handler that asserts the completion/failure of it. They return a copy of the future you passed as parameter For example this callback style assertion: 1234methodThatReturnsAFuture().setHandler(testContext.succeding(result -&gt; { // Some assertions // Call testContext.complete() or flag a checkpoint})); Turns into: 1234testContext.assertComplete(methodThatReturnsAFuture()).setHandler(asyncResult-&gt; { // Some assertions. Note that result is in asyncResult.result() // Call testContext.complete() or flag a checkpoint}); Nothing revolutionary, right? To appreciate it let&#x2019;s look at a more real use case Testing a Future chainLet&#x2019;s say that we want to test an update method of a class that manage some entities in a database. A common flow for this kind of tests is: Use the raw db client to add some data Use the class instance you want to test to update data on db Retrieve data from db to test if update is successfull Assuming that both raw db client and entity manager has futurized APIs, without these methods, this test translates in 3 nested callbacks. Now you can simplify it like this: 123456789testContext.assertComplete( rawClient.create(someData) .compose(addedData -&gt; myEntityManager.update(addedData.getId(), stuffToUpdate)) .compose(updatedData -&gt; rawClient.get(updatedData.getId()))).setHandler(resultAr -&gt; { // assertComplete guarantees that resultAr is completed // Do the assertions you want testContext.complete();}); With just one assertComplete() we assert that all chain of async operations completes without errors. Then I set an handler that does the final assertions before completing the test Now, let&#x2019;s assume that you want to do the same test as before but testing a failure of your method. To do it you need to check every single step of future chain: 12345678910testContext.assertComplete(rawClient.create(someData)) .compose(addedData -&gt; testContext.assertFailure(myEntityManager.update(addedData.getId(), stuffToUpdate))) .recover(failedAr -&gt; { // Do some assertions on failedAr.cause() return testContext.assertComplete(rawClient.get(failedAr.cause().getEntityId())); }) .setHandler(resultAr -&gt; { // Do the assertions you want testContext.complete(); }); Tricks and tipsThe bad thing of future chains is passing values through the chain. Let&#x2019;s say that in previous example the exception throwed by update() method doesn&#x2019;t return an exception that contains a super handy method like getEntityId(). But to get the data from db you need the id of your data instance, so how you can solve it? You have two ways that really depend on your code style: If you are a bit more functional, use CompositeFuture.join() to transform a tuple of Futures (one of them already completed with the value you want to pass through the chain) to a single Future that encapsulates both the previous async operation result and the new result. This method works only when you are in a chain of completed handlers because when a future inside CompositeFuture.join() fails, the &#x201C;join future&#x201D; is not an instance of CompositeFuture and doesn&#x2019;t return any information about other joined futures. I prefer to avoid this method, but keep it in mind because you can find it useful sometimes. If you don&#x2019;t care about functional stuff, just use old but gold AtomicReferences: 1234567891011121314AtomicReference&lt;String&gt; entityId = new AtomicReference&lt;&gt;();testContext.assertComplete(rawClient.create(someData)) .compose(addedData -&gt; { entityId.set(addedData.getId()); return testContext.assertFailure(myEntityManager.update(addedData.getId(), stuffToUpdate)) }) .recover(failedAr -&gt; { // Do some assertions on failedAr.cause() return testContext.assertComplete(rawClient.get(entityId.get())); }) .setHandler(resultAr -&gt; { // Do the assertions you want testContext.complete(); }); If you have any good tips don&#x2019;t hesitate to contact me! Happy testing! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>vertx</tag>
        <tag>development</tag>
        <tag>testing</tag>
        <tag>junit5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Routing with Eclipse Collections]]></title>
    <url>%2FRouting-With-Eclipse-Collections%2F</url>
    <content type="text"><![CDATA[I found days ago the Eclipse Collections library (ex Goldman Sachs Collections). Yes, that Goldman Sachs, one of the biggest investing banking group of the world, that for hobby creates super fast collection library for Java. This article follows the previous, when I explored how to improve the routing of Vert.x Web, so please check it out before reading this one: Tree vs SkipList routing What&#x2019;s newThree days ago, looking at my twitter wall, I&#x2019;ve found a tweet about Eclipse Collections. I&#x2019;ve found really interesting the performances of EC, so I&#x2019;ve decided to put it into my benchmark and test it on our use case. I obviously choose the tree as data structure to rewrite the routing process of Vert.x Web, so I have write two variants of my original TreeRouter: ECTreeRouter: A tree that internally uses List implementations of Eclipse Collections. ImmutableECTreeRouter: A tree that internally uses immutable List implementations of Eclipse Collections. In this case user can&#x2019;t change the routing tree after routing has started. The second option was a pure experiment: user creates the router and its internal tree doesn&#x2019;t change during the application execution. In this case you have a simpler implementation and an immutable list (in some cases faster than a mutable one). I&#x2019;ve also refactored only the SocialNetworkBenchmark, because we have similar results on ECommerceBenchmark. ResultsAnd, as in the previous articles, here comes the graphs: Benchmark results for SocialNetworkBenchmark based on requested URLs Benchmark results for SocialNetworkBenchmark based on requested URLs with 10 random requests Final benchmark results for SocialNetworkBenchmark (&#x201C;with load&#x201D; values properly scaled) And in the end the &#x201C;final test&#x201D; graph (now it does only random requests, not sequentially): Final benchmark results for SocialNetworkBenchmark I have some considerations about these results: Eclipse Collections are fast to iterate, faster than JDK&#x2019;s collections, so probably they are good for our use case. In particular, pay attention to particular events generated from benchmark data: ECTreeRouter is faster than skip list in /feed request in &#x201C;without load&#x201D; tests! In particular it creates interesting deltas from TreeRouter when we request constant paths&#x2026; But going deeper doesn&#x2019;t help the ECTreeRouter, in particular in &#x201C;without load&#x201D; benchmarks. We have too few datas to assert that at deeper levels ECTreeRouter drops its performances or aligns it with TreeRouter ECTreeRouter, without any doubt, in the random requests test is faster than TreeRouter Eclipse Collections contains a lot of optimized iteration patterns optimized, maybe useful for us It seems that EC thread-safe lists are faster than immutable lists, so the ImmutableECTreeRouter is a failed experiment &#x1F625; Unlike the previous post I&#x2019;m little hesitant to give a verdict, but we have promising results with Eclipse Collections, so I want to start with it. In case we experience &#x201C;not so good&#x201D; performances after the implementation, migrate back to JDK&#x2019;s collections doesn&#x2019;t appear a complicated task Stay tuned for other updates! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>web development</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
        <tag>routing</tag>
        <tag>data structures</tag>
        <tag>tree</tag>
        <tag>skiplist</tag>
        <tag>eclipse collections</tag>
        <tag>fast list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tree vs SkipList routing]]></title>
    <url>%2FRouting-Tree-vs-SkipList%2F</url>
    <content type="text"><![CDATA[One of the most important features of web frameworks is performance and the routing process can become an important performance killer. I&#x2019;m going to introduce you a comparison between the list (in particular the skip list) and the tree as data structure for web framework&#x2019;s routers. Why this articleRouting consists in calling the correct handler for the URL that user requested. Sometimes this can be a simple and fast process, but in modern scenarios most times this process slows your application, in particular when: You have a huge list of routes You rely on path parameters (sometimes 2 or more path parameters in the same route) You want to run multiple handlers for every URL segment I&#x2019;m writing this article because I want to implement a tree router inside Vert.x Web framework, so I&#x2019;m investigating around to find what the best solution would be. List routing vs Tree routingA Route is a combination of HTTP method and path. The path can be a simple constant path or a path with one or more parameters, managed via regular expressions. The list routing uses a list to contain all defined routes (in a precise order). When the server receives a request, the router iterates through the list and searches for the routes that match with the received request. This process cannot be a simple list search, because a request can match multiple times. For example: if we have a router that declares GET &quot;/&quot; GET &quot;/users&quot; GET &quot;/users/userA&quot; and we receive /users/userA as request, the router has to run all the handlers of these three routes. The tree routing differs from list routing for one simple thing: the routes are inside a tree. So when the router receives the request, it follows the tree searching for matching routes When you think about a website (or, in the same situation, a web API) you think about a tree of web pages (operations) you can retrieve (perform). But most of the web frameworks don&#x2019;t implement the routing as a tree of resources, for multiple reasons: It&#x2019;s difficult to build a routing codebase around a concurrent tree preserving good performances Does the user manually build the routing tree or is the insertion a task for the algorithm? And how can we manage the regular expressions inside this insertion algorithm? Modern lists (for example the SkipList) are really powerful and can obtain performances similar to trees mantaining the routing codebase simple But, not considering these problems, the tree seems a better solution for this problem, right? This is the starting thesis, now I need to prove it. Before starting, I want to underline that some frameworks have succesfully implemented the tree routing, for example Fastify, achieving really interesting performances Reproduce the two types of routersThe first step is creating the sketches of these two routing mechanisms. I&#x2019;ve tried to create the list routing similar to Vert.x Web router, but of course these are only simplified examples. The router of a web framework is more complex than my 50 lines of code. The list router is implemented inside class ListRouter and tree router is implemented inside class TreeRouter. The list router has a simple loop that calls for every route the function route(); when this function returns true, the route matches perfectly and the routing process stops. Remember that when I check if route matches (both in tree and list scenario) the router: first checks if the path matches partially (in case of regexes it calls lookingAt() method, while in string paths it calls the method startsWith()) Then it checks if the path matches totally (methods matches() and equals()). If the path matches totally, the routing stops The tree routing is a simple recursive function that works as follow: Base case: The path chunk is empty so we have finished the routing succesfully If not base case: We try to match partially first the constant paths and then the regular expressions. If we found a match, we go deeper with recursion If we don&#x2019;t find any match the requested route doesn&#x2019;t exist and the routing process stops We test against path chunks for a simple reason: when we go deeper with recursion we don&#x2019;t need to test against previous path components (and we don&#x2019;t need to re-extract the parameters), so the router simply removes it from the requested URL. And of course when the string is empty we have finished the routing. To gain good performances inside tree nodes I used the skip lists (I know I&#x2019;ve cheated) to contain associated routes. This is only a way to implement the tree routing and also remember that I haven&#x2019;t written the insertion algorithm for the tree router, so I do all association between nodes manually. Two common API scenariosI&#x2019;ve created two benchmarks: an example of ecommerce API and a social network API. This examples are really similar, they only differ in number of routes and how many regular expression are contained in said routes. Below you can see how this &#x201C;fake&#x201D; routers are composed. Router created for ECommerceBenchmark Router created for SocialNetworkBenchmark Maybe Skip List is better?The first benchmarks I wrote are simple accesses to routes. I wrote one benchmark for every route (that I store in compatiblePaths) and every data structure. Below you can find results of ECommerceBenchmark: Benchmark results for ECommerceBenchmark based on requested URLs The first observation is that the constant paths in skip list are faster than in the tree router. This is caused by skip list optimization: when we get the same elements multiple times the skip list optimizes its links to access more quickly to its values. But the performances for skip lists falls in favor of tree when we use regular expressions, because of course we give a smaller string to the regular expression engine. With the /health path we have a little difference because in tree we are at the first level, while in /user/newUser we are one level deeper than /health. This results are confirmed by the SocialNetworkBenchmark with the same configuration: Benchmark results for SocialNetworkBenchmark based on requested URLs So maybe skip lists are so fast that trees are not competitive in this application field? I&#x2019;ve done two considerations: In a real case situation a router doesn&#x2019;t receive 12.000.000 same requests in one second, but maybe if it receives 1.000 same requests (for example the /feed request) the skip list optimization helps a lot My tree implementation is rude compared to JDK&#x2019;s ConcurrentSkipListSet And if I add some spice?To confuse the skip list I&#x2019;ve created a more real scenario: The benchmark function does 10 random requests and then the request assigned. This process complicates things a bit for the skip list, because it loses the optimization: Benchmark results for ECommerceBenchmark based on requested URLs with 10 random requests And of course it&#x2019;s a win for the tree. The fun fact is that tree defeats the skip list also in first paths. For the social benchmark the random function that chooses the 10 requests is little bit hacky: Some paths (for example the /feed) have more chances than other ones. But the results remain the same: Benchmark results for SocialNetworkBenchmark based on requested URLs with 10 random requests The results on SocialNetworkBenchmark are impressive because with some paths we have 3x or more performances for tree router, but we have an unstable situation at the same level. There&#x2019;s also an important consideration to do: When we go deeper, tree performances slope down, so to write a good tree router we need a good combination of access optimizations and insertion algorithm that avoids creating uselessly deep nodes. You can find below the final results with and without load (&#x201C;with load&#x201D; values conveniently scaled x11): Final benchmark results for ECommerceBenchmark Final benchmark results for SocialNetworkBenchmark And it&#x2019;s not finished!For the two test cases and data structures I also wrote a final benchmark that accesses to compatiblePaths sequentially and in both cases it&#x2019;s a huge win for tree: Final results (left e-commerce benchmark, right social benchmark) But this is not a very realistic situation, because usually we have a situation like the social network benchmark with load: we have more frequent requests and less frequent requests, but it&#x2019;s unusual to get requests ordered in the router order sequentially. So, what&#x2019;s better?That&#x2019;s an hard question, because these examples don&#x2019;t prove a lot. But, according to this data, it makes sense to start developing a tree router because we have good preconditions. In some situations with regular expressions we have seen up to 2x performances thanks to the tree router, but it&#x2019;s important to get good performances also with constant paths (remember that when we have query parameters like /user?q=blabla these URLs are splitted at the start of routing and the router treats this requests like constant paths). Implementing a Tree Router: challenging tasksInsertion algorithmThe insertion algorithm is the most important challange for different reasons: Providing an optimization at every insertion Splitting constant paths and mostly importantly Splitting regular expressions The idea of insertion is not splitting for every / (like I&#x2019;ve done in my examples) but something more like this: At the start we have an empty root node When I add a route I assign it to the root node When I add another route I check if it&#x2019;s a child of the root node or if I can split the root node in two nodes. In the first case I simply add the new route inside the list of childs, in the second case I split the root node creating two child nodes and assigning to the root node the shared first part of path For example: Path inserted Tree update Empty root node /users/{user_id} Root node with assigned &#x201C;/users/{user_id}&#x201D; /users/addUser Root node assigned with &#x201C;/users/&#x201C; and with childs &#x201C;{user_id}&#x201D; and &#x201C;addUser&#x201D; /users/addFacebookUser &#x201C;addUser&#x201D; splitted in new node with &#x201C;add&#x201D; and childs &#x201C;User&#x201D; and &#x201C;FacebookUser&#x201D; The last task in particular is very tricky, because a simple char to char comparison is very limiting and also can generate not working regular expressions. For example: path /([a-b]{0, 9}) and path /([a-z]{0, 9}) cannot be splitted creating a parent node with /([a, because of course this regular expression is invalid. I&#x2019;ve got some ideas about it: First I check if two routes have the same regular expressions in the middle. For example when we have /users/{user_id}/feed and /users/{user_id}/events we split it into /users/{user_id}/ with childs feed and events. This can be done with some regular expressions If a regular expression is at the end of a path, I split at the last constant / (not inside a group). If none of the previous, I treat it as first level child To do these things maybe a library that helps &#x201C;understanding&#x201D; regular expressions could come in handy. Mantaining good performances during routingI really don&#x2019;t have idea how &#x1F604;. I want to start creating a simple router that does only the minimal routing and then I add conditions necessary to successfully pass the tests. Maybe operating in this way I can avoid creation of useless code. ConclusionsRouter Tree is possible and can give great performances to Vert.x Web. I cannot wait to start working on it! Stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>web development</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
        <tag>routing</tag>
        <tag>data structures</tag>
        <tag>tree</tag>
        <tag>skiplist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My GSoC 2017 - Slush-vertx]]></title>
    <url>%2FMy-GSoC-2017-Slush-Vertx%2F</url>
    <content type="text"><![CDATA[slush-vertx is a project created by Paulo Lopes born to simplify build tools configurations for Vert.x. I totally refactored slush-vertx to create a multi purpose code generator for simplify various configurations of Vert.x powered projects. Multi purpose and simple to enlargeWhen I designed the new slush-vertx, I tried to create a Vert.x project generator for every configuration needed, not only an OpenAPI 3 server or OpenAPI 3 client. Another important variable of my project is create a generator that generates code for different languages and different build tools. Now slush-vertx It&#x2019;s like a &#x201C;code generation hub&#x201D;: It contains a set of project generators, based on what type of Vert.x project are you going to scaffold. At the moment I&#x2019;m writing this post, slush-vertx contains: Vert.x Starter project generator: Based on original Paulo&#x2019;s project, generates an empty project configured for Vert.x 3 Framework Vert.x Web Server Starter generator: Generates a skeleton with sources and tests for Vert.x 3 Web powered REST server Vert.x Web Server OpenAPI project generator: Generates a skeleton based on Swagger 2/OpenAPI 3 specification with sources and tests for Vert.x 3 Web powered REST server Vert.x Web Client OpenAPI project generator: Generates a client based on a Swagger 2/OpenAPI 3 specification and Vert.x 3 Web Client I hope it will grow in the future, creating a tool that can help people to connect with Vert.x world. How it works Behind the scenesslush-vertx is metadata and template driven code generator. This means: For every language/build tool it has a set of metadata, that can be extended with user inputs It uses a template engine to generate code, based on metadata If you want a complete scenario of behaviours of slush-vertx, give a look at this wiki page But, why that complexity behind a code generator? I mean, It&#x2019;s only a code generator! Yes, It&#x2019;s only a code generator, but I wanted to create a tool simple to extend with new generators routines, giving to Eclipse Vert.x a powerful tool. Generate unit testsSo, if you have a powerful build tool that generates pretty everything you want, why don&#x2019;t take advantage of it doing things that you don&#x2019;t want to do? And this is what I&#x2019;ve done! Copy-pasting code from other generators I&#x2019;ve created, I builded a unit test generator for vertx-web-api-contract-openapi. This generator takes all operations declared in this oas 3 spec and generates a specific test to validate the correct parsing of parameters on server side. This is the final result: OpenAPI3ParametersUnitTest.java. This unit tests helped me a lot to complete the vertx-web-api-contract-openapi module. With some small changes this can be a complete server libraries/frameworks compatibility test tool for OpenAPI 3 And now?Now use it! Follow the readme inside GitHub repository to install and start using it. You can also contribute to this project adding new generators and updating existing ones with new languages document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>openapi</tag>
        <tag>web development</tag>
        <tag>gsoc 2017</tag>
        <tag>gsoc</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
        <tag>openapi3</tag>
        <tag>generator</tag>
        <tag>slush-vertx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My GSoC 2017 - OpenAPI 3 Vert.x support]]></title>
    <url>%2FMy-GSoC-2017-OAS3-Router-Factory%2F</url>
    <content type="text"><![CDATA[The support to OpenAPI 3 it&#x2019;s located in maven package vertx-web-api-contract-openapi, and most classes extends/subclass from interfaces/classes inside maven package vertx-web-api-contract-common (the package designed to contain all API Specs standards common classes). Most important interfaces of vertx-web-api-contract-openapi are: The OpenAPI3ValidationHandler class that fills BaseValidationHandler maps The OpenAPI3RouterFactory, the interface that enable users create a router with your API spec As I said in a previous blog post, OpenAPI 3 added a lot of new things, in particular about serialization styles and complex form bodies (url encoded and multipart). So when I started working on OpenAPI 3 requests validations, I had to add a lot of things to validation framework that I haven&#x2019;t expected before. The validation handlerOpenAPI3ValidationHandler is an interface extension of HTTPOperationRequestValidationHandler (located inside vertx-web-api-contract-common), that is an interface extension of ValidationHandler. This class contains all methods to elaborate the Operation object (Java representation of OAS3 operation object) and the list of Parameter objects (Java representation of OAS3 parameter object). When constructed, it generates all ParameterValidationRule and ParameterTypeValidator it needs: in fact, It doesn&#x2019;t elaborate the api spec nor work with api spec Java models during the validation. It does everything when It&#x2019;s constructed, so It iterates through various parameters and It generates objects needed for validation. If you read this class, It seems messy, because It&#x2019;s messy &#x1F604;. This is because of complexity of OAS 3, that forced me to write some little tricks to support all things (like for example to manage the deepObject serialization style). To give a quick explanation of how this class elaborates parameters: It checks if it&#x2019;s supported (parameters with allowReserved: true are not supported) It checks if the parameter needs a workaround to get validation working and applies the specific workaround If none workaround is needed, it constructs the correct type validator Behind the scenes all the validation work is done by validation framework The router factoryThe router factory is intended to give the most simple user interface to generate a router based on an API Spec. In fact, it provides this functionalities: Async loading of specification and its schema dependencies OpenAPI 3 compliant API specification validation (thanks to Kaizen-OpenApi-Parser) Load handlers and failure handlers with operationId Automatic 501 (Not implemented) response for operations with missing handlers (can be enabled/disabled with mountOperationsWithoutHandlers(boolean)) Automatic ValidationException failure handler (can be enabled/disabled with enableValidationFailureHandler() and manually configured with setValidationFailureHandler()) Path&#x2019;s regular expression generation (to support matrix and label style unsupported natively from Vert.x) Lazy methods: the generation of the Router is done only when you call getRouter() Automatic mount of security validation handlers Lazy methodsIt&#x2019;s usual to run into problems regards route declaration order. For example if you declare two routes in this order: GET /hello/{parameter} GET /hello/world With actual Vert.x Router implementation, /hello/world handler will never called, unless you explicitly call RoutingContext#next() inside /hello/{parameter} handler (that causes Router to run the next route matching the pattern). With lazy methods It&#x2019;s guaranteed that routes will be loaded with order declared inside API specification. I choose lazy methods also for code style reasons, It helps a lot to manage the code of router factory. And the final resultWith this tools, user can bring OpenAPI 3 power to its Vert.x server implementation as simple as: 123456789101112131415161718192021222324252627282930313233OpenAPI3RouterFactory.createRouterFactoryFromFile(this.vertx, &quot;src/main/resources/petstore.yaml&quot;, ar -&gt; { if (ar.succeeded()) { // Spec loaded with success OpenAPI3RouterFactory routerFactory = ar.result(); // Add some handlers routerFactory.addHandlerByOperationId(&quot;listPets&quot;, routingContext -&gt; { RequestParameters params = routingContext.get(&quot;parsedParameters&quot;); // Handle listPets operation }); routerFactory.addFailureHandlerByOperationId(&quot;listPets&quot;, routingContext -&gt; { Throwable failure = routingContext.failure(); // Something really bad happened during listPets handling }); // Add a security handler routerFactory.addSecurityHandler(&quot;api_key&quot;, routingContext -&gt; { // Handle security here and then call next() routingContext.next(); }); // Now you have to generate the router Router router = routerFactory.getRouter(); // Now you can use your Router instance HttpServer server = vertx.createHttpServer(new HttpServerOptions().setPort(8080).setHost(&quot;localhost&quot;)); server.requestHandler(router::accept).listen(); } else { // Something went wrong during router factory initialization Throwable exception = ar.cause(); } }); Next time I&#x2019;m going to introduce you slush-vertx, a new generator for Vert.x project. Stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>openapi</tag>
        <tag>web development</tag>
        <tag>gsoc 2017</tag>
        <tag>gsoc</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
        <tag>openapi3</tag>
        <tag>router factory</tag>
        <tag>factory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My GSoC 2017 - Requests validation]]></title>
    <url>%2FMy-GSoC-2017-Validation%2F</url>
    <content type="text"><![CDATA[HTTP request validation it&#x2019;s a critical component of my project. HTTP requests validation needs to work well to get working all layers upon. I love to call that vertx-web validation framework (I love the word framework &#x1F60D;) Structure of Validation frameworkThe validation framework is located inside maven module vertx-web and package io.vertx.ext.web.validation. Following the Vert.x rules, there are Java interfaces for polyglot vertx-web interface and classes inside io.vertx.ext.web.validation.impl that implements the logic of the validation. HTTPRequestValidationHandler and OpenAPI3RequestValidationHandler (request validator for OAS3) subclass BaseValidationHandler, the base class for validation. This class contains a map with parameter names as keys and ParameterValidationRule instances as values for every parameter location (query, path, header, cookie, form inside body). Every ParameterValidationRule contains a ParameterTypeValidation. To simplify things: BaseValidationHandler validates the request, in fact it iterates through parameters and calls ParameterValidationRule methods ParameterValidationRule abstracts a parameter and validates if parameter exists, if can be empty, &#x2026; ParameterTypeValidator abstracts the parameter type and validates the type An example of BaseValidationHandler instance Every exceptions of validation framework are encapsulated inside ValidationException class. Types of parametersMost important part of validation is type validation. Type validation take a string or a list of strings as input and gives the parameter correctly parsed as output. I&#x2019;ve built a rich set of type validators (mostly to support OpenAPI 3 parameter types): NumericTypeValidator to validate integers and floating point values StringTypeValidator to validate strings against a pattern BooleanTypeValidator to validate booleans JsonTypeValidator and XMLTypeValidator to validate json and xml against a schema EnumTypeValidator to validate enums ObjectTypeValidator and ArrayTypeValidator to validate objects and array AnyOfTypeValidator and OneOfTypeValidator to validate json schema like anyOf and oneOf To instance this classes, there are static methods inside ParameterTypeValidator. Of course, user can subclass ParameterTypeValidator to create its custom type validator. I&#x2019;ve also created a set of prebuilt instances of this type validators inside ParameterType enum, with some common patterns like hostname, email, &#x2026; Encapsulating parsed parametersAfter type validation parameter is parsed and then encapsulated in an object called RequestParameter. Every object is mapped into equivalent language type, for example: if we declare a parameter as integer, we receive (in Java) Integer object. When user wants to handle parameters, he can retrieve the RequestParameters from RoutingContext. RequestParameters encapsulate all RequestParameter objects filtered by location. For example: 1234567router.get(&quot;/awesomePath&quot;) .handler(superAwesomeValidationHandler) .handler(routingContext -&gt; { RequestParameters params = routingContext.get(&quot;parsedParameters&quot;); RequestParameter awesomeParameter = params.queryParameter(&quot;awesomeParameter&quot;); Integer awesome = awesomeParameter.getInteger();}); Arrays, objects and serialization stylesUser can declare arrays and objects as parameters. The ObjectTypeValidator/ArrayTypeValidator provides the deserialization from string, the validation of objects fields/array items with &#x201C;nested&#x201D; validators and the encapsulation inside map/list. For example, you can declare a query parameter as comma separated array of integers like this one: ?q=1,2,3,4,5 and you will receive as result a List&lt;Integer&gt;. The serialization methods are implemented as subclasses of ContainerDeserializer and there are some prebuilt instances in enum ContainerSerializationStyle. Of course, user can use static methods inside ObjectTypeValidator.ObjectTypeValidatorFactory and ArrayTypeValidator.ArrayTypeValidatorFactory to build this validators, define its serialization style and add the &#x201C;nested&#x201D; validators. HTTPRequestValidationHandlerTo start validate the requests, developers can use the HTTPRequestValidationHandler. This class exposes methods to add validators without care about ParameterValidationRule, because they are automatically generated. For every parameter location HTTPRequestValidationHandler exposes three methods: add*Param: to add a parameter with type taken from ParameterType enum add*ParamWithPattern: to add a string parameter with a pattern add*ParamWithCustomTypeValidator: to add a parameter with an instance of ParameterTypeValidator Then there are methods for body, like addJsonBodySchema or addMultipartRequiredFile Next time I&#x2019;m going to introduce you the OAS 3 Router Factory, stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>web development</tag>
        <tag>gsoc 2017</tag>
        <tag>gsoc</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
        <tag>http validation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My GSoC 2017 - Small recap of my summer]]></title>
    <url>%2FMy-GSoC-2017-Recap%2F</url>
    <content type="text"><![CDATA[I love to code, I code for passion and then for work.Lot of people asked me if, excluding money, it&#x2019;s really interesting to work on an open source project. I found so interesting that I can do that for free and for a lot of reasons: increase skills, help the community, promote myself and work on code that I haven&#x2019;t wrote! Mixing the two things I said, Google Summer of Code is perfect for me! Small story of my GSoC 2017 projectAs my project page says, my object is implement the api design driven development techniques inside vertx-web. Actually the first idea was to implement OpenAPI 2 (fka Swagger) and RAML, then this happened. With OpenAPI 3 at horizon we decided to focus on it, because, as for Swagger 2, OpenAPI 3 have converters from old specification versions to newest one. As my mentor says, we are pioneers of OAS 3 &#x1F604;. For OpenAPI 3 parsing, we decided to use Kaizen-OpenAPI-Parser and I often helped this new project with pull requests.But I kept the idea to abstract as much as possible the router factory and the validation methods to enable future implementations of new api specification standards. I&#x2019;ve also created an interface for users to validate HTTP requests without writing an api spec. Also, to complete my work, I wrote a lot of unit testsAt the end of implementation of validation and router factory for OAS 3, I wrote a lot of documentation and also a blog post on Eclipse Vert.x blog After the first evaluation phase, I refactored the code splitting it in different maven packages. Then I started focusing on code generation: swagger-codegen doesn&#x2019;t support for now OAS 3, and they don&#x2019;t know when they will release OAS 3 support, so we decided to create our generator. Basing on my mentor&#x2019;s project, I started creating the code generator. I&#x2019;ve done huge changes from original project, to enable it to add different generators to same project and support different languages and package managers. I&#x2019;ve also take advantage of this work to generate new unit tests for OAS 3 router factory and validation (with a tremendous first run &#x1F622;). I&#x2019;ve also done other pull requests to vertx-web complementary to my work. I added a method to get query parameters and I enabled Route object to contain multiple handlers (like Express middlewares). Before the end of the summer, I will give to Vert.x a set of classes for HTTP requests validation, OAS 3 support and a generator multi-purpose simple to extend with new templates. In the next articles I&#x2019;m going to discuss about all technical things about my project, stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>web development</tag>
        <tag>gsoc 2017</tag>
        <tag>gsoc</tag>
        <tag>vertx</tag>
        <tag>vertx web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What's new in OpenAPI Specification 3 - Parameters]]></title>
    <url>%2FWhats-New-In-OAS3-Parameters%2F</url>
    <content type="text"><![CDATA[OpenAPI 3 Parameter Object it&#x2019;s totally different from old OpenAPI 2. It gives the power to describe complex parameters, using the power of Schema object. I will introduce to you this breaking changes No more form and body parametersOne of the major changes is that body parameters (forms, json, &#x2026;) are moved to a new object called RequestBody. So now Parameter supports only request parameters in: header query path and the new one cookie schema is better than typeIn OpenAPI 2 a parameter is defined as:12345parameters: - name: smile in: query type: string format: ([;:]-*([()\[\]])\2*) # Smile regex In OpenAPI 3 you can find the same parameter as:123456parameters: - name: smile in: query schema: type: string format: ([;:]-*([()\[\]])\2*) # Smile regex The major difference is that now you have to define a schema for every single parameter, even the most simple. It seems annoying, but It gives some interesting opportunities. For example: A model identifier has a particular regular expression (format) that describes it and you want to write CRUD methods for this model. This is what you have to do in OpenAPI 2:123456789101112131415# get pathparameters: - name: id in: query schema: type: string format: ^[a-z]{3}[0-9]{10}$# delete pathparameters: - name: id in: query schema: type: string format: ^[a-z]{3}[0-9]{10}$# And so on Now with OpenAPI 3 you can define this single string as a schema and reference to it where you want:1234567891011121314151617181920# define your identifier schema in components/schemacomponents: schemas: my_model_identifier: type: string format: ^[a-z]{3}[0-9]{10}$# get pathparameters: - name: id in: query schema: $ref: &apos;#/components/schemas/my_model_identifier&apos;# delete pathparameters: - name: id in: query schema: $ref: &apos;#/components/schemas/my_model_identifier&apos;# And so on You can also reuse it to define complete model:123456789101112components: schemas: my_model_identifier: type: string format: ^[a-z]{3}[0-9]{10}$ my_model: type: object parameters: id: $ref: &apos;#/components/schemas/my_model_identifier&apos; other_field: type: string Objects inside path/query/header parametersThis is tricky, but actually it&#x2019;s possible. With Schema object support you can define object as query, header, cookie, path parameter. This is an example:12345678910111213parameters: - name: parameter in: query schema: type: object properties: a: type: integer b: type: string required: - a - b I will explain later how to submit this type of requests One interesting usage is when you have multi-dimensional key for a model, for example a geolocation model. Serialization style changesstyle is the new name of collectionFormat field. But It isn&#x2019;t only a name change. Also style is supported by another field: exploded. This is the comparison table with OpenAPI 2 style explode OpenAPI 2 collectionFormat matrix false not supported matrix true not supported label false not supported label true not supported form false csv form true multi simple false csv simple true csv (not for object) spaceDelimited false ssv pipeDelimited false pipes deepObject true not supported {: .table} For more informations about how to use this two new fields, check out this table. Complex parameters with contentIf you think schema isn&#x2019;t enough, check out content field. I will explain this further when I will cover RequestBody Tips to create a good parameter object in OpenAPI 3 Try to keep parameters as simple as possible. Avoid as much as possible objects and arrays, They create only a lot of headaches Use query parameters if you need to pass arrays to operation and use form style Pass objects to an operation with RequestBody, or split it in different primitive parameters. Take as much as possible advantage of schema inside Parameter object. In particular use it to define object identifiers document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>swagger</tag>
        <tag>openapi</tag>
        <tag>web development</tag>
        <tag>web api</tag>
        <tag>openapi3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Why use Web API specifications?]]></title>
    <url>%2FWhy-Use-API-Specification%2F</url>
    <content type="text"><![CDATA[You can see Web API Specifications like Javadoc: you can&#x2019;t use a Java library without Javadoc! Web API spec are &#x201C;Javadocs&#x201D; of web services. But there&#x2019;s one big difference: you can write your Web API Spec before start writing your server. It generates a big difference inside development process. I will introduce you to this magic world. Design Driven DevelopmentDesign Driven Development is the name of technique which consists in: write the Web API spec before start writing any other code. Then, when you start writing code, you already have implemented a &#x201C;dictionary&#x201D; of server-client interface, so front-end and back-end developers go straight to implement logic of application. If you choose the right tools, you don&#x2019;t have to care about: What is the correct HTTP Request to do something If you have done request with correct and valid parameters If logged user has correct requirements to complete the operation requested The flexibility of Web API specifications enables this to be used for a lot of use cases: Develop a SPA (single page application) with back-end in any language and front-end in Javascript Develop a mobile application with back-end in any language and front-end natives Develop a web service with backend in every language and auto-generate clients for every language Approaches to use Web API Specification in you projectBoth client and server can be linked to Web API Spec through two different approches: Static code generation Dynamic code generation Static code generation is the most simple to achieve, you can find a code generation library for every language/framework/api specification standard combination. Depending on your project and on library you use it can be useful approach or not. It&#x2019;s a really interesting approach on client-side, but it lacks of flexibility in server side. Most code generators on server side create a stub of server code, with all validation and security routines generated directly from code generator. It can be really useful when you write an Web API Spec that you assert that will wont&#x2019;t change during development of back-end. One important feature of static code generation is represented by performances, so I prefer this for a web service project Dynamic code generation is the most interesting for server side of small project. You can change your spec every time you want, and server will generate new validation flow. It&#x2019;s interesting when you write a client-server complete stack, and you change spec during development. Small projectsDo you want to write a magic mobile/web application with a couple of your friends that do something astonishing? Use this tools: OpenAPI specification 2 (version 3 is newer, but you can&#x2019;t find tools related) Node.JS backend with dynamic code generation library (I suggest swaggerize-express) Static client code generators Good feeling between you and your friends when you write the spec :) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
      <tags>
        <tag>swagger</tag>
        <tag>openapi</tag>
        <tag>web development</tag>
        <tag>web api</tag>
        <tag>backend</tag>
        <tag>frontend</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello world!]]></title>
    <url>%2FHello-World!%2F</url>
    <content type="text"><![CDATA[This is one of my favourite sentences. Really, when you read hello world on console you know that you have taken the correct path to reach your objective. I read this sentence a lot of times in my console, and every time I&#x2019;m comforting read it. It gives me the power to write &quot;hello world&quot; + name. Languages I knowI&#x2019;ve practiced hello world in different languages: C++ Java Javascript Python And others&#x2026; And I want to practice it in a lot of other different languages, because, as you probably know, in IT world we never stop learning. My loves: Javascript and JavaJavascript is my favourite language. You can use this language for everything you want: desktop app, mobile app, web app, backend, &#x2026; It has like an infinite catalogue of libraries for every need! I&#x2019;m a little bit experienced with Node.JS/Express stack, and a lot of related libraries. I&#x2019;m also experienced with OpenAPI specification, and all related tools (Swagger Editor, swaggerize-express, &#x2026;). For me Java is like big brother of Javascript. But if you love Javascript, you love Java too. I know little bit of Java-EE, Android development and I&#x2019;m learning right now Eclipse Vert.x for GSoC 2017 So, don&#x2019;t get surprised if i&#x2019;m going to talk a lot about Java and Javascript! The guys that I want to know better: C++ and PythonI&#x2019;ve got a small experience with C++ and Python, but I&#x2019;m going to improve my skills. This languages are a must have in a developer portfolio! Why a blog?I&#x2019;m going to write a blog because I want to document my experiences and share my projects. And also, I think it will be funny! Stay tuned! document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });]]></content>
  </entry>
</search>
